import streamlit as st
import requests
import io
import sounddevice as sd
import scipy.io.wavfile as wav
import threading
import time
from gtts import gTTS
import os
import pygame
import base64
from PIL import Image

st.set_page_config(page_title="Multi-Modal Korean ChatBot", layout="wide")

# API ì—”ë“œí¬ì¸íŠ¸ ì„¤ì •
CHAT_API_ENDPOINT = "chat_api"
IMAGE_API_ENDPOINT = "stable_diffusion_api/generate_image"

st.sidebar.title("ì±—ë´‡ ì •ë³´")
st.sidebar.info(
    "ì´ ì±—ë´‡ì€ ìŒì„± ì¸ì‹, Llama3 ëª¨ë¸, ê·¸ë¦¬ê³  ì´ë¯¸ì§€ ìƒì„± ê¸°ëŠ¥ì„ í†µí•©í•œ ì‹œìŠ¤í…œì…ë‹ˆë‹¤. "
    "ìŒì„±ìœ¼ë¡œ ì§ˆë¬¸í•˜ê±°ë‚˜ í…ìŠ¤íŠ¸ë¡œ ì…ë ¥í•  ìˆ˜ ìˆìœ¼ë©°, 'ê·¸ë¦¼ê·¸ë ¤ì¤˜'ë¼ê³  ìš”ì²­í•˜ë©´ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
)

st.sidebar.title("ì‚¬ìš© ë°©ë²•")
st.sidebar.markdown(
    """
    1. 'ìŒì„± ë…¹ìŒ' ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ 5ì´ˆ ë™ì•ˆ ìŒì„±ì„ ë…¹ìŒí•˜ì„¸ìš”.
    2. ë…¹ìŒì´ ì™„ë£Œë˜ë©´ ìë™ìœ¼ë¡œ ì„œë²„ë¡œ ì „ì†¡ë©ë‹ˆë‹¤.
    3. ë˜ëŠ” ì±„íŒ… ì…ë ¥ì°½ì— í…ìŠ¤íŠ¸ë¡œ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.
    4. 'ê·¸ë¦¼ê·¸ë ¤ì¤˜'ì™€ ê°™ì€ ë¬¸êµ¬ë¥¼ í¬í•¨í•˜ë©´ ì´ë¯¸ì§€ê°€ ìƒì„±ë©ë‹ˆë‹¤.
    5. AIê°€ ì‘ë‹µì„ ìƒì„±í•˜ê³  ìŒì„±ìœ¼ë¡œ ì½ì–´ì¤ë‹ˆë‹¤.
    6. ëŒ€í™” ê¸°ë¡ì€ ìë™ìœ¼ë¡œ ì €ì¥ë©ë‹ˆë‹¤.
    """
)

def record_audio(duration=5, sample_rate=16000):
    audio_data = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1)
    sd.wait()
    return audio_data, sample_rate

def send_audio_get_response(audio_data, sample_rate):
    audio_buffer = io.BytesIO()
    wav.write(audio_buffer, sample_rate, audio_data)
    audio_buffer.seek(0)
    
    files = {'file': ('audio.wav', audio_buffer, 'audio/wav')}
    response = requests.post(f"{CHAT_API_ENDPOINT}/speech_to_chat", files=files)
    
    if response.status_code == 200:
        return response.json()
    else:
        return {"transcription": "Error: Unable to process audio.", "response": "Error: Unable to get response from the server."}

def send_text_get_response(text):
    response = requests.post(f"{CHAT_API_ENDPOINT}/chat", json={"message": text})
    if response.status_code == 200:
        return response.json()["response"]
    else:
        return "Error: Unable to get response from the server."

def text_to_speech(text):
    tts = gTTS(text=text, lang='ko')
    tts.save("response.mp3")
    
    pygame.mixer.init()
    pygame.mixer.music.load("response.mp3")
    pygame.mixer.music.play()
    while pygame.mixer.music.get_busy():
        pygame.time.Clock().tick(10)
    pygame.mixer.quit()
    
    os.remove("response.mp3")

def generate_image(prompt):
    response = requests.post(IMAGE_API_ENDPOINT, json={
        "prompt": prompt,
        "negative_prompt": "",
        "num_inference_steps": 28,
        "guidance_scale": 7.0
    })
    if response.status_code == 200:
        image_data = base64.b64decode(response.json()["image"])
        return Image.open(io.BytesIO(image_data))
    else:
        st.error(f"Error: {response.status_code}")
        return None

def record_and_send():
    with st.spinner("ìŒì„±ì„ ë…¹ìŒ ì¤‘..."):
        audio_data, sample_rate = record_audio()
    
    with st.spinner("ìŒì„±ì„ ì²˜ë¦¬ ì¤‘..."):
        result = send_audio_get_response(audio_data, sample_rate)
    
    transcription = result['transcription']
    if "ê·¸ë¦¼" in transcription:
        with st.spinner("ì´ë¯¸ì§€ ìƒì„± ì¤‘..."):
            image = generate_image(transcription)
            if image:
                st.session_state.messages.append({"role": "assistant", "image": image})
                st.image(image)
                response = "ì´ë¯¸ì§€ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤."
            else:
                response = "ì´ë¯¸ì§€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
    else:
        response = result['response']
    
    st.session_state.messages.append({'role': 'user', 'content': f"{transcription}"})
    st.session_state.messages.append({'role': 'assistant', 'content': response})
    
    text_to_speech(response)

def main():
    st.title('ğŸ¤– Multimodal ChatBot - ìŒì„±, í…ìŠ¤íŠ¸, ì´ë¯¸ì§€ í†µí•© AI')
    
    if 'messages' not in st.session_state:
        st.session_state.messages = []

    for message in st.session_state.messages:
        with st.chat_message(message['role']):
            if "content" in message:
                st.markdown(message['content'])
            if "image" in message:
                st.image(message['image'])

    if st.sidebar.button("ìŒì„± ë…¹ìŒ"):
        record_and_send()
        st.experimental_rerun()

    st.sidebar.title("ê°œë°œì ì •ë³´")
    st.sidebar.markdown(
        """
        - **ê°œë°œì**: ì •ê°•ë¹ˆ
        - **ë²„ì „**: 2.0.0
        """
    )

    if prompt := st.chat_input('ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”'):
        st.session_state.messages.append({'role': 'user', 'content': prompt})
        with st.chat_message('user'):
            st.markdown(prompt)

        with st.chat_message('assistant'):
            if "ê·¸ë¦¼ê·¸ë ¤ì¤˜" in prompt or "ì´ë¯¸ì§€ ìƒì„±" in prompt:
                with st.spinner("ì´ë¯¸ì§€ ìƒì„± ì¤‘..."):
                    image = generate_image(prompt)
                    if image:
                        st.session_state.messages.append({"role": "assistant", "image": image})
                        st.image(image)
                        response = "ì´ë¯¸ì§€ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤."
                    else:
                        response = "ì´ë¯¸ì§€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
            else:
                with st.spinner('ë‹µë³€ ìƒì„± ì¤‘...'):
                    response = send_text_get_response(prompt)
            
            st.markdown(response)
            st.session_state.messages.append({'role': 'assistant', 'content': response})
            text_to_speech(response)

if __name__ == "__main__":
    main()
